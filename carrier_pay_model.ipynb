{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrier Pay Prediction (Super Dispatch-style)\n",
    "\n",
    "This notebook builds an end-to-end ML pipeline to predict `Carrier_Pay` from shipment quote data using scikit-learn Pipelines and ColumnTransformer. It follows best practices: data cleaning, preprocessing, model comparison with cross-validation (RMSE, RÂ²), hyperparameter tuning, and model persistence.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- Quote_Id (will be dropped)\n",
    "- Customer\n",
    "- Vehicle_Types\n",
    "- Mode(no HH)\n",
    "- Total_Vehicles\n",
    "- Origin_City\n",
    "- Destination_City\n",
    "- Origin_State\n",
    "- Destination_State\n",
    "- Origin_Zip\n",
    "- Destination_Zip\n",
    "- Miles\n",
    "- Tariff\n",
    "- GP\n",
    "- Carrier_Pay (target)\n",
    "\n",
    "If your CSV isn't present at `DATA_CSV_PATH`, this notebook auto-loads a small sample so it still runs end-to-end. Adjust `DATA_CSV_PATH` to your file before training on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost available: True\n"
     ]
    }
   ],
   "source": [
    "# Imports & setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# XGBoost optional\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "# OneHotEncoder compatibility for different sklearn versions\n",
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "print(f'XGBoost available: {HAS_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV: C:\\Users\\omp\\CascadeProjects\\rw_ml\\data\\quote_report_feb_dispatched.xlsx with shape (1201, 18)\n"
     ]
    }
   ],
   "source": [
    "# Configure data path (update this if needed)\n",
    "DATA_CSV_PATH = Path('data/quote_report_feb_dispatched.xlsx')  # Change to your file path if different\n",
    "\n",
    "# If your CSV isn't available, we will auto-load a tiny sample so the notebook runs end-to-end.\n",
    "SAMPLE_ROWS = [\n",
    "    {\n",
    "        'Quote_Id': 248092, 'Customer': 'Residential - Sales Jason Mishko', 'Vehicle_Types': 'Sedan Midsize(op)', 'Mode(no HH)': 'Open',\n",
    "        'Total_Vehicles': 1, 'Origin_City': 'Palm Coast', 'Destination_City': 'Springfield', 'Origin_State': 'Florida', 'Destination_State': 'Missouri',\n",
    "        'Origin_Zip': '32137', 'Destination_Zip': '65806', 'Miles': 1068, 'Tariff': 850, 'Carrier_Pay': 700, 'GP': 150\n",
    "    },\n",
    "    {\n",
    "        'Quote_Id': 249030, 'Customer': 'Advantage Car Rental', 'Vehicle_Types': 'SUV Mid-size(op)', 'Mode(no HH)': 'Open',\n",
    "        'Total_Vehicles': 1, 'Origin_City': 'Pearl', 'Destination_City': 'Orlando', 'Origin_State': 'Mississippi', 'Destination_State': 'Florida',\n",
    "        'Origin_Zip': '39208', 'Destination_Zip': '32812', 'Miles': 691, 'Tariff': 1000, 'Carrier_Pay': 600, 'GP': 400\n",
    "    },\n",
    "    {\n",
    "        'Quote_Id': 249289, 'Customer': 'Enterprise Fleet Management', 'Vehicle_Types': 'SUV(op)', 'Mode(no HH)': 'Open',\n",
    "        'Total_Vehicles': 1, 'Origin_City': 'Schenectady', 'Destination_City': 'Cologne', 'Origin_State': 'New York', 'Destination_State': 'New Jersey',\n",
    "        'Origin_Zip': '12304', 'Destination_Zip': '08215', 'Miles': 1, 'Tariff': 500, 'Carrier_Pay': 475, 'GP': 25\n",
    "    },\n",
    "]\n",
    "\n",
    "if DATA_CSV_PATH.exists():\n",
    "    df_raw = pd.read_excel(DATA_CSV_PATH,header=1)\n",
    "    print(f'Loaded CSV: {DATA_CSV_PATH.resolve()} with shape {df_raw.shape}')\n",
    "else:\n",
    "    print(f'CSV not found at {DATA_CSV_PATH.resolve()}. Using an in-notebook sample to demonstrate the full pipeline.')\n",
    "    df_raw = pd.DataFrame(SAMPLE_ROWS)\n",
    "    print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f4bbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Quote  Id', 'Customer', 'Vehicle Types', 'Mode(no HH)',\n",
       "       'Total Vehicles', 'Origin City', 'Destination City', 'Origin State',\n",
       "       'Destination State', 'Origin Zip', 'Destination Zip', 'Miles', 'Tariff',\n",
       "       'Carrier Pay', 'GP', 'Tariff.1', 'Carrier Pay.1', 'GP.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Quote  Id': 'quote_id',\n",
    "    'Customer': 'customer',\n",
    "    'Vehicle_Types': 'vehicle_types',\n",
    "    'Mode(no HH)': 'mode',\n",
    "    'Total_Vehicles': 'total_vehicles',\n",
    "    'Origin_City': 'origin_city',\n",
    "    'Destination_City': 'destination_city',\n",
    "    'Origin_State': 'origin_state',\n",
    "    'Destination_State': 'destination_state',\n",
    "    'Origin_Zip': 'origin_zip',\n",
    "    'Destination_Zip': 'destination_zip',\n",
    "    'Miles': 'miles',\n",
    "    'Tariff': 'tariff',\n",
    "    'Carrier_Pay': 'carrier_pay',\n",
    "    'GP': 'gp',\n",
    "    'Tariff.1': 'tariff_api',\n",
    "    'Carrier Pay.1': 'carrier_pay_api',\n",
    "    'GP.1': 'gp_api'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (1201, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote  Id</th>\n",
       "      <th>Customer</th>\n",
       "      <th>Vehicle Types</th>\n",
       "      <th>Mode(no HH)</th>\n",
       "      <th>Total Vehicles</th>\n",
       "      <th>Origin City</th>\n",
       "      <th>Destination City</th>\n",
       "      <th>Origin State</th>\n",
       "      <th>Destination State</th>\n",
       "      <th>Origin Zip</th>\n",
       "      <th>Destination Zip</th>\n",
       "      <th>Miles</th>\n",
       "      <th>Tariff</th>\n",
       "      <th>Carrier Pay</th>\n",
       "      <th>GP</th>\n",
       "      <th>Tariff.1</th>\n",
       "      <th>Carrier Pay.1</th>\n",
       "      <th>GP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248092</td>\n",
       "      <td>Residential - Sales Jason Mishko</td>\n",
       "      <td>Sedan Midsize(op)</td>\n",
       "      <td>Open</td>\n",
       "      <td>1</td>\n",
       "      <td>Palm Coast</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>32137</td>\n",
       "      <td>65806</td>\n",
       "      <td>1068</td>\n",
       "      <td>850.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>700</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249030</td>\n",
       "      <td>Advantage Car Rental</td>\n",
       "      <td>SUV Mid-size(op)</td>\n",
       "      <td>Open</td>\n",
       "      <td>1</td>\n",
       "      <td>Pearl</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Florida</td>\n",
       "      <td>39208</td>\n",
       "      <td>32812</td>\n",
       "      <td>691</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>642.86</td>\n",
       "      <td>450</td>\n",
       "      <td>192.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249289</td>\n",
       "      <td>Enterprise Fleet Management</td>\n",
       "      <td>SUV(op)</td>\n",
       "      <td>Open</td>\n",
       "      <td>1</td>\n",
       "      <td>Schenectady</td>\n",
       "      <td>Cologne</td>\n",
       "      <td>New York</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>12304</td>\n",
       "      <td>8215</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>350</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249582</td>\n",
       "      <td>Enterprise Fleet Management</td>\n",
       "      <td>Sedan Midsize(op)</td>\n",
       "      <td>Open</td>\n",
       "      <td>1</td>\n",
       "      <td>Maitland</td>\n",
       "      <td>Rogers Park</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>32751</td>\n",
       "      <td>60626</td>\n",
       "      <td>1145</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>928.57</td>\n",
       "      <td>650</td>\n",
       "      <td>278.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249618</td>\n",
       "      <td>Premier Auto Finance</td>\n",
       "      <td>Sedan Midsize(inop)</td>\n",
       "      <td>Open</td>\n",
       "      <td>1</td>\n",
       "      <td>Ocala</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>34479</td>\n",
       "      <td>33023</td>\n",
       "      <td>293</td>\n",
       "      <td>550.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>571.43</td>\n",
       "      <td>400</td>\n",
       "      <td>171.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quote  Id                          Customer        Vehicle Types  \\\n",
       "0     248092  Residential - Sales Jason Mishko    Sedan Midsize(op)   \n",
       "1     249030              Advantage Car Rental     SUV Mid-size(op)   \n",
       "2     249289       Enterprise Fleet Management              SUV(op)   \n",
       "3     249582       Enterprise Fleet Management    Sedan Midsize(op)   \n",
       "4     249618              Premier Auto Finance  Sedan Midsize(inop)   \n",
       "\n",
       "  Mode(no HH)  Total Vehicles  Origin City Destination City Origin State  \\\n",
       "0        Open               1   Palm Coast      Springfield      Florida   \n",
       "1        Open               1        Pearl          Orlando  Mississippi   \n",
       "2        Open               1  Schenectady          Cologne     New York   \n",
       "3        Open               1     Maitland      Rogers Park      Florida   \n",
       "4        Open               1        Ocala        Hollywood      Florida   \n",
       "\n",
       "  Destination State  Origin Zip  Destination Zip  Miles  Tariff  Carrier Pay  \\\n",
       "0          Missouri       32137            65806   1068   850.0        700.0   \n",
       "1           Florida       39208            32812    691  1000.0        600.0   \n",
       "2        New Jersey       12304             8215      0   500.0        475.0   \n",
       "3          Illinois       32751            60626   1145  1350.0        750.0   \n",
       "4           Florida       34479            33023    293   550.0        500.0   \n",
       "\n",
       "      GP  Tariff.1  Carrier Pay.1    GP.1  \n",
       "0  150.0   1000.00            700  300.00  \n",
       "1  400.0    642.86            450  192.86  \n",
       "2   25.0    500.00            350  150.00  \n",
       "3  600.0    928.57            650  278.57  \n",
       "4   50.0    571.43            400  171.43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Missing required columns: ['customer', 'vehicle_types', 'mode', 'origin_city', 'destination_city', 'origin_state', 'destination_state', 'miles', 'tariff', 'gp', 'total_vehicles', 'carrier_pay']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m missing = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mMissing required columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Missing required columns: ['customer', 'vehicle_types', 'mode', 'origin_city', 'destination_city', 'origin_state', 'destination_state', 'miles', 'tariff', 'gp', 'total_vehicles', 'carrier_pay']"
     ]
    }
   ],
   "source": [
    "# Data cleaning utilities\n",
    "expected_categorical = ['customer','vehicle_types','mode','origin_city','destination_city','origin_state','destination_state']\n",
    "expected_numeric = ['miles','tariff','gp','total_vehicles']\n",
    "target_col = 'carrier_pay'\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Drop exact duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove irrelevant identifier if present\n",
    "    if 'quote_Id' in df.columns:\n",
    "        df = df.drop(columns=['quote_Id'])\n",
    "\n",
    "    # Ensure ZIPs are strings if present\n",
    "    for col in ['origin_zip','destination_zip']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Convert numerics\n",
    "    for col in ['miles','tariff','gp','total_vehicles', target_col]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Normalize categorical: strip whitespace\n",
    "    for col in [c for c in expected_categorical if c in df.columns]:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Remove invalid/zero/NaN mileage rows\n",
    "    before = len(df)\n",
    "    if 'miles' in df.columns:\n",
    "        df = df[df['miles'].notna()]\n",
    "        df = df[df['miles'] > 0]  # drop zero or negative miles\n",
    "    removed = before - len(df)\n",
    "    if removed:\n",
    "        print(f'Removed {removed} rows with invalid miles (<=0 or NaN).')\n",
    "\n",
    "    # Remove rows with missing target if present\n",
    "    if target_col in df.columns:\n",
    "        before = len(df)\n",
    "        df = df[df[target_col].notna()]\n",
    "        removed_t = before - len(df)\n",
    "        if removed_t:\n",
    "            print(f'Removed {removed_t} rows with missing {target_col}.')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_data(df_raw)\n",
    "print('Cleaned shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Validate required columns exist\n",
    "required_cols = expected_categorical + expected_numeric + [target_col]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f'Missing required columns: {missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering via FunctionTransformer\n",
    "def add_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    # Per-mile features (Miles>0 enforced by cleaning)\n",
    "    if 'Miles' in X.columns and 'Tariff' in X.columns:\n",
    "        denom = X['Miles'].replace(0, np.nan)\n",
    "        X['tariff_per_mile'] = X['Tariff'] / denom\n",
    "    if 'Miles' in X.columns and 'GP' in X.columns:\n",
    "        denom = X['Miles'].replace(0, np.nan)\n",
    "        X['gp_per_mile'] = X['GP'] / denom\n",
    "    # Origin/Destination same-state flag\n",
    "    if 'Origin_State' in X.columns and 'Destination_State' in X.columns:\n",
    "        X['is_same_state'] = (\n",
    "            X['Origin_State'].astype(str).str.strip().str.lower()\n",
    "            == X['Destination_State'].astype(str).str.strip().str.lower()\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        X['is_same_state'] = 0\n",
    "    return X\n",
    "\n",
    "feature_adder = FunctionTransformer(add_features, validate=False)\n",
    "\n",
    "categorical_cols = expected_categorical\n",
    "numeric_base = expected_numeric\n",
    "derived_numeric = ['tariff_per_mile','gp_per_mile','is_same_state']\n",
    "numeric_all = numeric_base + derived_numeric\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', make_ohe()),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_all),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X = df[categorical_cols + numeric_base].copy()\n",
    "y = df[target_col].values\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model pipelines\n",
    "def build_pipelines():\n",
    "    models = {}\n",
    "    models['linreg'] = Pipeline(steps=[\n",
    "        ('features', feature_adder),\n",
    "        ('preprocess', preprocess),\n",
    "        ('model', LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    models['rf'] = Pipeline(steps=[\n",
    "        ('features', feature_adder),\n",
    "        ('preprocess', preprocess),\n",
    "        ('model', RandomForestRegressor(\n",
    "            n_estimators=400,\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    models['gbr'] = Pipeline(steps=[\n",
    "        ('features', feature_adder),\n",
    "        ('preprocess', preprocess),\n",
    "        ('model', GradientBoostingRegressor(random_state=SEED)),\n",
    "    ])\n",
    "\n",
    "    if HAS_XGB:\n",
    "        models['xgb'] = Pipeline(steps=[\n",
    "            ('features', feature_adder),\n",
    "            ('preprocess', preprocess),\n",
    "            ('model', XGBRegressor(\n",
    "                n_estimators=600,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_lambda=1.0,\n",
    "                objective='reg:squarederror',\n",
    "                n_jobs=-1,\n",
    "                random_state=SEED,\n",
    "                tree_method='hist',\n",
    "                verbosity=0\n",
    "            )),\n",
    "        ])\n",
    "    return models\n",
    "\n",
    "models = build_pipelines()\n",
    "print('Models:', list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base models with cross-validation\n",
    "def evaluate_models(models, X, y):\n",
    "    n_samples = len(y)\n",
    "    if n_samples < 2:\n",
    "        raise ValueError('Not enough rows to evaluate models.')\n",
    "    cv_splits = min(5, n_samples)\n",
    "    if cv_splits < 2:\n",
    "        # Fallback simple holdout\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=SEED)\n",
    "        rows = []\n",
    "        for name, pipe in models.items():\n",
    "            pipe.fit(X_train, y_train)\n",
    "            pred = pipe.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "            r2 = r2_score(y_test, pred)\n",
    "            rows.append({'model': name, 'rmse_mean': rmse, 'rmse_std': np.nan, 'r2_mean': r2, 'r2_std': np.nan, 'fit_time_s': np.nan})\n",
    "        return pd.DataFrame(rows).sort_values('rmse_mean')\n",
    "    else:\n",
    "        cv = KFold(n_splits=cv_splits, shuffle=True, random_state=SEED)\n",
    "        rows = []\n",
    "        for name, pipe in models.items():\n",
    "            res = cross_validate(\n",
    "                pipe, X, y, cv=cv, n_jobs=-1,\n",
    "                scoring={'rmse': 'neg_root_mean_squared_error', 'r2': 'r2'},\n",
    "                return_train_score=False, error_score='raise'\n",
    "            )\n",
    "            rows.append({\n",
    "                'model': name,\n",
    "                'rmse_mean': -res['test_rmse'].mean(),\n",
    "                'rmse_std': res['test_rmse'].std(),\n",
    "                'r2_mean': res['test_r2'].mean(),\n",
    "                'r2_std': res['test_r2'].std(),\n",
    "                'fit_time_s': res['fit_time'].mean(),\n",
    "            })\n",
    "        return pd.DataFrame(rows).sort_values('rmse_mean')\n",
    "\n",
    "results_df = evaluate_models(models, X, y)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning (optimize RMSE) for the best-performing model\n",
    "def get_search_space(model_name):\n",
    "    if model_name == 'rf':\n",
    "        return {\n",
    "            'model__n_estimators': [200, 400, 600, 800],\n",
    "            'model__max_depth': [None, 10, 15, 20],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 2, 4],\n",
    "            'model__max_features': ['sqrt', 'log2', 0.5],\n",
    "        }\n",
    "    if model_name == 'gbr':\n",
    "        return {\n",
    "            'model__n_estimators': [200, 400, 600],\n",
    "            'model__learning_rate': [0.05, 0.1, 0.2],\n",
    "            'model__max_depth': [2, 3, 4],\n",
    "            'model__subsample': [0.6, 0.8, 1.0],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 2, 4],\n",
    "            'model__max_features': ['sqrt', 'log2', None],\n",
    "        }\n",
    "    if model_name == 'xgb' and HAS_XGB:\n",
    "        return {\n",
    "            'model__n_estimators': [400, 600, 800],\n",
    "            'model__learning_rate': [0.03, 0.05, 0.1],\n",
    "            'model__max_depth': [4, 6, 8],\n",
    "            'model__subsample': [0.7, 0.9, 1.0],\n",
    "            'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'model__reg_lambda': [0.0, 1.0, 3.0],\n",
    "            'model__reg_alpha': [0.0, 0.1, 0.5],\n",
    "            'model__min_child_weight': [1, 3, 5],\n",
    "        }\n",
    "    return None\n",
    "\n",
    "best_base = results_df.iloc[0]['model']\n",
    "print('Best base model:', best_base)\n",
    "param_space = get_search_space(best_base)\n",
    "\n",
    "if param_space is None:\n",
    "    print('No hyperparameters to tune or unsupported model. Proceeding with base model.')\n",
    "    best_pipeline = models[best_base]\n",
    "    best_pipeline.fit(X, y)\n",
    "    best_cv_score = results_df.iloc[0]['rmse_mean']\n",
    "    tuned = False\n",
    "else:\n",
    "    # RandomizedSearchCV for efficiency\n",
    "    cv_splits = min(5, len(y))\n",
    "    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=SEED) if cv_splits >= 2 else 3\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=models[best_base],\n",
    "        param_distributions=param_space,\n",
    "        n_iter=25,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "        verbose=1,\n",
    "        refit=True,\n",
    "        error_score='raise'\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    best_pipeline = search.best_estimator_\n",
    "    best_cv_score = -search.best_score_\n",
    "    tuned = True\n",
    "\n",
    "print(f'Tuned: {tuned}')\n",
    "if tuned:\n",
    "    print('Best hyperparameters:')\n",
    "    print(json.dumps(search.best_params_, indent=2))\n",
    "print(f'Best CV RMSE: {best_cv_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned/best pipeline with cross-validation for both RMSE and R^2\n",
    "cv_splits = min(5, len(y))\n",
    "if cv_splits >= 2:\n",
    "    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=SEED)\n",
    "    res = cross_validate(\n",
    "        best_pipeline, X, y, cv=cv, n_jobs=-1,\n",
    "        scoring={'rmse': 'neg_root_mean_squared_error', 'r2': 'r2'},\n",
    "        return_train_score=False\n",
    "    )\n",
    "    final_rmse = -res['test_rmse'].mean()\n",
    "    final_r2 = res['test_r2'].mean()\n",
    "else:\n",
    "    # Fallback simple holdout\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.33, random_state=SEED)\n",
    "    best_pipeline.fit(X_tr, y_tr)\n",
    "    preds = best_pipeline.predict(X_te)\n",
    "    final_rmse = mean_squared_error(y_te, preds, squared=False)\n",
    "    final_r2 = r2_score(y_te, preds)\n",
    "\n",
    "print(f'Final CV/holdout RMSE: {final_rmse:.4f} | R^2: {final_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on full data and save the final model\n",
    "best_pipeline.fit(X, y)\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = models_dir / 'carrier_pay_model.joblib'\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "\n",
    "metrics = {\n",
    "    'best_base_model': str(results_df.iloc[0]['model']),\n",
    "    'tuned': bool(tuned),\n",
    "    'best_cv_rmse': float(best_cv_score),\n",
    "    'final_rmse': float(final_rmse),\n",
    "    'final_r2': float(final_r2)\n",
    "}\n",
    "with open(models_dir / 'carrier_pay_model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f'Model saved to: {model_path.resolve()}')\n",
    "print('Metrics saved to:', (models_dir / 'carrier_pay_model_metrics.json').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: predict on a few rows\n",
    "sample_preds = best_pipeline.predict(X.head(5))\n",
    "pd.DataFrame({\n",
    "    'Carrier_Pay_actual': y[:5],\n",
    "    'Carrier_Pay_pred': sample_preds\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
